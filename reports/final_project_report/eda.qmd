# Pre-Processing and Exploratory Data Analysis
Once you have your dataset, you need to preprocess it to make it suitable for machine learning. This includes cleaning the data, handling missing values, encoding categorical variables, and scaling numerical features. This step is crucial as the accuracy of your model will depend on the quality of your data. 

## Dataset Collection
The Steam dataset was retrieved from Kaggle.com. See references for a direct link.

## Data Pre-processing

Some issues to consider to be included:
-  There were no missing values in the steam.csv dataset. Since the dataset did not have any missing values, there was no observable pattern of missing values and they did not have to be explicitly dealt with.

- To interpret the data, one-hot encoding was utilized. To keep the performance efficient and accurate. We decided to filter out some data. For example, after the dataset was cleaned up and formatted correctly, there was a column corresponding to every tag and category on Steam. Many of these columns were extremely niche so they were removed entirely. Only the best fitting categories and tags were considered and selected using SelectKBest to ensure proper performance and to remove any unwanted bias from one-hot encoding.

- Scaling variables in this dataset were considered and tested, however, it did not yield favourable results as the performance metrics on various models were less than what they previously were without any scaling. In particular, attempts were made to scale the positive ratings and negative rating columns, as these values were quite different from other numerical columns.

- There were relatively few outliers in the dataset and they were dealt with by removing them during processing. These outliers were either columns that represented very niche categories or game titles that did not have any ASCII values within the title. For example, Some titles were listed in Mandarin instead of English which caused problems so they were ultimately removed. 

- Does transforming the data simplify any analysis? Transforming the dataset using One-hot encoding played a vital role in simplifying our analysis. This is because our dataset had either values of 1 or 0 depending on if they fall under a certain category which helps as some models may provide unwanted results just using labels. One-hot encoding essentially puts all of these binary values in an easily understood array which allows it to be accurately tested on a variety of models.

## Exploratory Data Analysis and Visualisations 

Some of the steps, included here:

- Data visualization: Data visualization is the process of creating graphs and charts to help you understand the patterns and trends in the data. This step can help you identify outliers and anomalies in the data. Several attempts were made to better visualize which categories seemed to correlate to a higher number of owners. A bar graph was made to visualize the difference between how many single-player games and multiplayer games make up the total number of games owned. The results were that the majority of games owned on Steam were single-player games which insinuates that individuals may be more likely to purchase a single-player game. Another bar graph was made to show the number of owners for various price ranges. This graph was made to observe if individuals were more likely to purchase a game if it was on the cheaper side of the spectrum rather than a premium price. This likely turned out to be true as the majority of games owned were in the price ranges of free-to-play or less than $15. Another bar graph was created to show if certain developers tend to be more successful when it comes to selling their games. This graph took the total amount of owners from each developer and compared them against each other to find the 5 most successful developers. This graph was disproportionate, as Valve had the largest number of owners for their games. For a different perspective, another graph was created that excluded any free-to-play games. The result is different and the developers are much closer to each other in terms of owners of their games. A scatterplot graph was created to find a correlation between the median playtime of a game and its price as player retention can be a valuable metric of a game's success. The results of the graph suggest that individuals are more likely to put more time into free play and games on the cheaper side.


- Statistical analysis: Statistical analysis involves applying statistical methods to the data to identify patterns, trends, and relationships. This step can help you identify correlations between variables and understand the distribution of the data. This was covered under data visualization.

- Feature selection: Feature selection is the process of selecting the most important variables that will be used in the machine learning model. This step can help you identify which variables are most predictive and which variables can be ignored.  It was decided that the most important variables in this dataset would be category/tag, the number of positive ratings, the number of negative ratings, and the price of the game. A column representing the number of achievements of a game was ultimately dropped as it held little signficance. Each tag, genre, and category was represented as a column and this turned out to be an issue because there was a significant amount of them. Many of these columns also only corresponded to an extremely small percentage of the total games on the database. It was decided that these columns were to be dropped as it could skew results and these games would still be represented by other more frequently occuring tags and categories. The final processed dataset contained a sample of tags and categories according to SelectKBest. The decision to filter out entries that were before a certain date was to ensure that the data being analyzed is relevant to the current market.

- Dimensionality reduction: Dimensionality reduction is the process of reducing the number of variables in the data set. This step can help you reduce the complexity of the model and improve its performance. When the raw dataset was imported, categories, genres and tags were in a different format that likely would have causes problems later on. These values were essentially a string with the different categories/genres/tags separated by semicolons. In an effort to simplify the dataset, each string was split by semicolons, and each result was given its own column to make things more linear. 

